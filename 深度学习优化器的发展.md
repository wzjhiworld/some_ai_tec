# 深度学习学习器的发展

过去学习深度学习的时候，经常不能很好的阐述目前深度学习优化器的发展，以及他们的优缺点和解决的问题。  
今天就来好好的写一写，也算是以输出倒逼自己学习。

> https://blog.csdn.net/racesu/article/details/106382892  参考的博客

目前主流的优化器主要为以下几种：

* SGD
* Momentnum
* NAG 
* AdaGrad 
* RMSprop
* Adam
* AdamW
* Lars
* Lamb

## SGD

SGD 全称为批随机梯度下降，以一个 Batch 的样本计算梯度更新模型参数。  
相关公式如下：  

<a href="https://www.codecogs.com/eqnedit.php?latex=\theta&space;=&space;\theta&space;-&space;\eta&space;\cdot&space;{\nabla_{\theta}Loss}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta&space;=&space;\theta&space;-&space;\eta&space;\cdot&space;{\nabla_{\theta}Loss}" title="\theta = \theta - \eta \cdot {\nabla_{\theta}Loss}" /></a>

利用Loss 对权重参数 θ 求导，然后利用梯度进行参数 θ 的更新,其中 η 为学习率，用于控制学习过程的步长。  

SGD 随机梯度下降可能遇到的几个问题：

* 过小的学习率可能收敛过慢， 过大的学习率容易在峡谷形状或最优解附近震荡收敛困难， 所以一个合适的学习率是较难设置的。
* 在训练过程中调整学习率的化，那么一个合适的学习率改变计划也是一个难题，因为很难适应数据的特性。
* 所有的参数使用相同学习率是有问题的，如果数据分布很稀疏，所有的特征频率相差很大，需要以不同的程度更新所有的参数（类似于类不平衡问题），对于较少出现的特征需要使用更大的学习率。  
    > 想象这样一个场景，在一个分类网络的训练中，有一个Batch的数据中分别有四个对象分别为 [ 狗 狗 狗 猫 ] 因为每个样本回传的梯度的权重是一样，所以用于拟合狗的特征的参数其梯度会
    > 比较大，而用于拟合猫的特征的参数其梯度会很小，但是对网络的学习任务的重要性而言，每个参数的更新重要性应该是一致的，所以需要以不同的学习率来更新不同的网络参数有一定的合理性。
* 对于非凸平面的局部最小值和鞍点，鞍点的特点是周围的梯度都接近 0， 会导致梯度下降法局部失去效用，而无法找到更优解。

后续学界工业界为了解决或缓解上述问题，在 SGD 优化器的基础上提出了很多性能更优的优化器。

## Momentnum

Momentum 动量优化器在优化工程中，对于两种场景是具有优势的，分别如下：  

* 在梯度接近 0 的平坦位置，利用动量跳出平坦区域继续优化。
* 在遇到山谷等类型的 Loss 曲面时，可以通过动量的滤波优势，保持主要的前进方向，减少震荡。  

Momentum 的优化公式如下：

<a href="https://www.codecogs.com/eqnedit.php?latex=g_{t}&space;=&space;\gamma&space;g_{t-1}&space;&plus;&space;(1&space;-&space;\gamma)&space;\nabla_{\theta&space;}Loss" target="_blank"><img src="https://latex.codecogs.com/gif.latex?g_{t}&space;=&space;\gamma&space;g_{t-1}&space;&plus;&space;(1&space;-&space;\gamma)&space;\nabla_{\theta&space;}Loss" title="g_{t} = \gamma g_{t-1} + (1 - \gamma) \nabla_{\theta }Loss" /></a>  

<a href="https://www.codecogs.com/eqnedit.php?latex=\theta_{t}&space;=&space;\theta_{t-1}&space;-&space;\eta&space;\cdot&space;g_{t}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta_{t}&space;=&space;\theta_{t-1}&space;-&space;\eta&space;\cdot&space;g_{t}" title="\theta_{t} = \theta_{t-1} - \eta \cdot g_{t}" /></a>

其中参数 γ 动量系数。  

简单来说动量优化器的设计采用了类似于移动平均的理念，认为每一次一个Batch计算的梯度中都包含了很多的噪音，通过滑动平均的方式来滤除噪音，减少震荡。  
下图为 SGD 与 Momentum 的效果比较： 

![image](https://user-images.githubusercontent.com/78289886/121833002-fc807000-ccfd-11eb-8849-2d3a89a45e37.png)

## NAG

如果将优化的过程看成一个小球在 Loss 曲面上的滚动下降，那么加入动量后的小球会盲目地跟从下坡的梯度，容易发生错误。例如在一个先下坡在上坡的 Loss 曲面上，
小球向下滚动到最低点的时候，由于还存在动量的影响，小球会继续向上坡的方向行进，从而产生振荡，影响学习的进程。为了使小球变得更聪明，当小球知道对面使上坡
的时候提前降低速度，而不是冲上另一个坡。NAG 就是为了应对动量学习器出现该问题提出的自适应的方法。

![image](https://user-images.githubusercontent.com/78289886/122141670-62950080-ce80-11eb-908c-1ae2716836bd.png)

NAG 学习过程公式：  

<a href="https://www.codecogs.com/eqnedit.php?latex=g_{t}&space;=&space;\gamma&space;g_{t-1}&space;&plus;&space;(1&space;-&space;\gamma)&space;\cdot&space;\nabla_{\theta}Loss(\theta&space;-&space;\mu&space;\gamma&space;g_{t-1})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?g_{t}&space;=&space;\gamma&space;g_{t-1}&space;&plus;&space;(1&space;-&space;\gamma)&space;\cdot&space;\nabla_{\theta}Loss(\theta&space;-&space;\mu&space;\gamma&space;g_{t-1})" title="g_{t} = \gamma g_{t-1} + (1 - \gamma) \cdot \nabla_{\theta}Loss(\theta - \mu \gamma g_{t-1})" /></a>

<a href="https://www.codecogs.com/eqnedit.php?latex=\theta_{t}&space;=&space;\theta_{t-1}&space;-&space;\eta&space;\cdot&space;g_{t}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta_{t}&space;=&space;\theta_{t-1}&space;-&space;\eta&space;\cdot&space;g_{t}" title="\theta_{t} = \theta_{t-1} - \eta \cdot g_{t}" /></a>

NAG 利用 <a href="https://www.codecogs.com/eqnedit.php?latex=\theta&space;-&space;\mu&space;\cdot&space;\gamma&space;\cdot&space;g_{t-1}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta&space;-&space;\mu&space;\cdot&space;\gamma&space;\cdot&space;g_{t-1}" title="\theta - \mu \cdot \gamma \cdot g_{t-1}" /></a> 作为下个位置的估计值，而不是在当前位置计算梯度，这样就可以通过未来的位置信息来调整梯度，防止上述所出现的问题。

**问题**：从公式上看，NAG的计算过程需要先模拟未来位置的梯度，这在代码处理和梯度计算方面的消耗都要高于其他的一些同类优化器，可能就是目前很少见到使用的原因吧（猜测）。

## AdaGrad

> 核心思想：对频繁出现的特征执行更小的参数更新（低学习率），对于出现较少的特征予以更大的参数更新。所以该方法非常适用于处理稀疏数据，而且很大程度上提高了SGD的鲁棒性。

对于优化问题来说，随着梯度的增大，我们的步长也在增大， 在 AdaGrad 中随着梯度的增大， 分母增大，学习步长在减少，所以在优化的初始阶段，由于参数距离最优解比较远，所以  
需要大的步长，而随着训练的进行，参数开始接近最优解，这时候需要用小的步长微调。类似于学习率衰减的过程。

AdaGrad 的公式：  

<a href="https://www.codecogs.com/eqnedit.php?latex=\sigma&space;^{t}&space;=&space;\sqrt{\frac{1}{t&space;&plus;&space;1}\cdot&space;\sum_{i=0}^{t}&space;(g_{i})^{2}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\sigma&space;^{t}&space;=&space;\sqrt{\frac{1}{t&space;&plus;&space;1}\cdot&space;\sum_{i=0}^{t}&space;(g_{i})^{2}}" title="\sigma ^{t} = \sqrt{\frac{1}{t + 1}\cdot \sum_{i=0}^{t} (g_{i})^{2}}" /></a>  

<a href="https://www.codecogs.com/eqnedit.php?latex=\eta&space;^{t}&space;=&space;\frac{\eta&space;}{\sqrt{t&space;-&space;1}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\eta&space;^{t}&space;=&space;\frac{\eta&space;}{\sqrt{t&space;+&space;1}}" title="\eta ^{t} = \frac{\eta }{\sqrt{t + 1}}" /></a>  

<a href="https://www.codecogs.com/eqnedit.php?latex=\theta&space;^{t}&space;=&space;\theta&space;^{t-1}&space;-&space;\frac{\eta&space;^{t}}{\sigma&space;^{t}}\cdot&space;g_{t}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta&space;^{t}&space;=&space;\theta&space;^{t-1}&space;-&space;\frac{\eta&space;^{t}}{\sigma&space;^{t}}\cdot&space;g_{t}" title="\theta ^{t} = \theta ^{t-1} - \frac{\eta ^{t}}{\sigma ^{t}}\cdot g_{t}" /></a>

**final:**  

<a href="https://www.codecogs.com/eqnedit.php?latex=\theta&space;^{t}&space;=&space;\theta&space;^{t-1}&space;-&space;\frac{\eta&space;}{\sqrt{\sum_{i=1}^{t}&space;(g_{i})^{2}&space;&plus;&space;\epsilon&space;}}\cdot&space;g_{t}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta&space;^{t}&space;=&space;\theta&space;^{t-1}&space;-&space;\frac{\eta&space;}{\sqrt{\sum_{i=1}^{t}&space;(g_{i})^{2}&space;&plus;&space;\epsilon&space;}}\cdot&space;g_{t}" title="\theta ^{t} = \theta ^{t-1} - \frac{\eta }{\sqrt{\sum_{i=1}^{t} (g_{i})^{2} + \epsilon }}\cdot g_{t}" /></a>  

**为什么要除以梯度的平方和?**  

首先要知道 AdaGrad 其实是对于梯度较大的参数，用以较小的学习率，而对于梯度较小的参数，用以较大的学习率。这里面蕴含了一些牛顿迭代法的思想。  
利用梯度个平方和来模拟 Loss 的二阶梯度，因为直接计算 Loss 的二阶导数比较耗时。

**直观的理解**

在Loss空间中，较平缓的区域梯度值低需要较大的学习步长，而较陡的区域，如果使用同样的学习率，容易产生振荡，所以需要较小的学习步长来调整，这样
可以加快训练的过程。

**缺点**

* 从公式中可以看出，计算累积梯度平方和的时候，累积梯度平方和会越来越大，导致实际的学习率越来越小，阻碍后期的收敛
* 同上分析，要让训练过程得到一个合理的结果，必须要增对训练任务审计一个合适的全局初始化速率。

后续诞生的学习器弥补了 AdaGrad 的一些缺点。

## RMSProb

RMSProb 学习器用于解决 AdaGrad 由于梯度平方和累积一直变大导致学习步长持续下降的问题。所以在RMSProb中利用移动平均的方式计算累积的梯度平方  
和，这样就有效解决了梯度平方和累积得越来越大的问题。

**计算公式：**

<a href="https://www.codecogs.com/eqnedit.php?latex=\widetilde{g_{t}}&space;=&space;\lambda&space;\cdot&space;\widetilde{g}_{t-1}&space;&plus;&space;(1&space;-&space;\lambda)\cdot&space;g_{t}^{2}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\widetilde{g_{t}}&space;=&space;\lambda&space;\cdot&space;\widetilde{g}_{t-1}&space;&plus;&space;(1&space;-&space;\lambda)\cdot&space;g_{t}^{2}" title="\widetilde{g_{t}} = \lambda \cdot \widetilde{g}_{t-1} + (1 - \lambda)\cdot g_{t}^{2}" /></a>

<a href="https://www.codecogs.com/eqnedit.php?latex=\theta&space;_{t}&space;=&space;\theta&space;_{t-1}&space;-&space;\frac{\eta&space;}{\sqrt{\widetilde{g_{t}}&space;&plus;&space;\epsilon}}\cdot&space;g_{t}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta&space;_{t}&space;=&space;\theta&space;_{t-1}&space;-&space;\frac{\eta&space;}{\sqrt{\widetilde{g_{t}}&space;&plus;&space;\epsilon}}\cdot&space;g_{t}" title="\theta _{t} = \theta _{t-1} - \frac{\eta }{\sqrt{\widetilde{g_{t}} + \epsilon}}\cdot g_{t}" /></a>



